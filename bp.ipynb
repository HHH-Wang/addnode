{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape is:  (1797, 8, 8)\n",
      "the number of train:  1137\n",
      "the number of test:  360\n",
      "the number of validation:  300\n",
      "training data shape:  (1137, 64)\n",
      "validation data shape:  (300, 64)\n",
      "test data shape:  (360, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 加载sklearn自带的mnist数据\n",
    "digits = datasets.load_digits()\n",
    "# 数据集包含1797个手写体数字的图片，图片大小为8*8\n",
    "# 数字大小0～10，也就是说有这是个10分类问题\n",
    "images = digits.images\n",
    "targets = digits.target\n",
    "print((\"dataset shape is: \"), images.shape)\n",
    "# 将数据分为训练数据和测试数据（20%）\n",
    "X_train,X_test,y_train,y_test = train_test_split(images , targets , test_size=0.2 , random_state=0)\n",
    "num_training = 1137\n",
    "num_validation = 300\n",
    "num_test = y_test.shape[0]\n",
    "# 将训练集再分为训练集和验证集\n",
    "mask = list(range(num_training, num_training + num_validation))\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "print(\"the number of train: \", num_training)\n",
    "print(\"the number of test: \", num_test)\n",
    "print(\"the number of validation: \", num_validation)\n",
    "# 将每个数字8*8的像素矩阵转化为64*1的向量\n",
    "X_train = X_train.reshape(num_training, -1)\n",
    "X_val = X_val.reshape(num_validation, -1)\n",
    "X_test = X_test.reshape(num_test, -1)\n",
    "print(\"training data shape: \", X_train.shape)\n",
    "print(\"validation data shape: \", X_val.shape)\n",
    "print(\"test data shape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络的参数\n",
    "# 定义超参\n",
    "input_size = 64\n",
    "hidden_size = 30\n",
    "num_classes = 10\n",
    "# 为了之后使用的方便，我将参数初始化，计算loss，训练，预测的过程都定义在一个名为network的类中 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PycharmProject.cnn import network #从自定义的类中引出\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练30个隐藏节点的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 5000: loss 2.302587\n",
      "iteration 100 / 5000: loss 2.301861\n",
      "iteration 200 / 5000: loss 2.206225\n",
      "iteration 300 / 5000: loss 1.296984\n",
      "iteration 400 / 5000: loss 0.941002\n",
      "iteration 500 / 5000: loss 0.785880\n",
      "iteration 600 / 5000: loss 0.827294\n",
      "iteration 700 / 5000: loss 0.774106\n",
      "iteration 800 / 5000: loss 0.815422\n",
      "iteration 900 / 5000: loss 0.768211\n",
      "iteration 1000 / 5000: loss 0.787185\n",
      "iteration 1100 / 5000: loss 0.782876\n",
      "iteration 1200 / 5000: loss 0.791674\n",
      "iteration 1300 / 5000: loss 0.742254\n",
      "iteration 1400 / 5000: loss 0.780427\n",
      "iteration 1500 / 5000: loss 0.780346\n",
      "iteration 1600 / 5000: loss 0.702118\n",
      "iteration 1700 / 5000: loss 0.714850\n",
      "iteration 1800 / 5000: loss 0.743797\n",
      "iteration 1900 / 5000: loss 0.811183\n",
      "iteration 2000 / 5000: loss 0.738605\n",
      "iteration 2100 / 5000: loss 0.756463\n",
      "iteration 2200 / 5000: loss 0.718344\n",
      "iteration 2300 / 5000: loss 0.729844\n",
      "iteration 2400 / 5000: loss 0.759118\n",
      "iteration 2500 / 5000: loss 0.725241\n",
      "iteration 2600 / 5000: loss 0.767802\n",
      "iteration 2700 / 5000: loss 0.757908\n",
      "iteration 2800 / 5000: loss 0.743795\n",
      "iteration 2900 / 5000: loss 0.765313\n",
      "iteration 3000 / 5000: loss 0.719459\n",
      "iteration 3100 / 5000: loss 0.737569\n",
      "iteration 3200 / 5000: loss 0.745530\n",
      "iteration 3300 / 5000: loss 0.720123\n",
      "iteration 3400 / 5000: loss 0.733182\n",
      "iteration 3500 / 5000: loss 0.757327\n",
      "iteration 3600 / 5000: loss 0.731365\n",
      "iteration 3700 / 5000: loss 0.749581\n",
      "iteration 3800 / 5000: loss 0.735619\n",
      "iteration 3900 / 5000: loss 0.767432\n",
      "iteration 4000 / 5000: loss 0.763206\n",
      "iteration 4100 / 5000: loss 0.765382\n",
      "iteration 4200 / 5000: loss 0.755156\n",
      "iteration 4300 / 5000: loss 0.745295\n",
      "iteration 4400 / 5000: loss 0.724233\n",
      "iteration 4500 / 5000: loss 0.749359\n",
      "iteration 4600 / 5000: loss 0.761114\n",
      "iteration 4700 / 5000: loss 0.717478\n",
      "iteration 4800 / 5000: loss 0.749432\n",
      "iteration 4900 / 5000: loss 0.746032\n",
      "Train accuracy:  0.9630606860158312\n",
      "Validation accuracy:  0.9633333333333334\n",
      "test accuracy:  0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "net = network(input_size, hidden_size, num_classes)\n",
    "\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=5000, batch_size=200,\n",
    "            learning_rate=0.01, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "train_acc = (net.predict(X_train) == y_train).mean()\n",
    "print('Train accuracy: ', train_acc)\n",
    "\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)\n",
    "\n",
    "test_acc = (net.predict(X_test) == y_test).mean()\n",
    "print('test accuracy: ', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设计一个动态增加隐藏层节点的过程，从1开始，一直到训练准确率达到一个值为止。相当于每次训练的网络不一样，来找合适的超参数hiddensize。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设计一个可以扩充隐藏层节点的网络，从1个节点开始，一个循环结束，如果达不到准确率，增加一个节点然后继续训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义一个函数来重复100次，取平均训练时间，addnode1是扩充模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnode1(initnode):\n",
    "    #扩充节点模式，之前训练的参数保留\n",
    "    dy_hidden_size  = initnode \n",
    "    init_train_acc = 0\n",
    "    init_test_acc = 0\n",
    "    net1 = network(input_size, dy_hidden_size, num_classes)\n",
    "    for i in range(1,200):\n",
    "        stats = net1.train(X_train, y_train, X_val, y_val,\n",
    "                    num_iters=5000, batch_size=200,\n",
    "                    learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                    reg=0.25, verbose=False)\n",
    "\n",
    "        train_acc = (net1.predict(X_train) == y_train).mean()\n",
    "#         print('Train accuracy: ', train_acc)\n",
    "        test_acc = (net1.predict(X_test) == y_test).mean()\n",
    "#         print('test accuracy: ', test_acc)\n",
    "        if train_acc >0.96 and train_acc > test_acc:\n",
    "            print('Terminal hidden nodes number: ', dy_hidden_size)\n",
    "            break\n",
    "\n",
    "        #增加一个隐藏层节点，就是给权重矩阵扩充一列\n",
    "        dy_hidden_size = dy_hidden_size + 1\n",
    "\n",
    "        #给输入层的权重矩阵增加一列\n",
    "        c = np.random.randn(64,1)\n",
    "        net1.params_['W1'] = np.hstack((net1.params_['W1'],c))\n",
    "        #给输入层的偏置增加一个0\n",
    "        net1.params_['b1'] = np.append(net1.params_['b1'], np.zeros(1))\n",
    "        #给输入层的权重矩阵增加一行\n",
    "        d = np.random.randn(1,10)\n",
    "        net1.params_['W2'] = np.vstack((net1.params_['W2'],d))\n",
    "    return dy_hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  12\n",
      "Terminal hidden nodes number:  11\n",
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  9\n",
      "Terminal hidden nodes number:  9\n",
      "Terminal hidden nodes number:  15\n",
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  14\n",
      "Terminal hidden nodes number:  14\n",
      "avarge time:  15.4\n",
      "avarge nodes:  11.4\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "time1 = []\n",
    "node1 = []\n",
    "for i in range(10):\n",
    "    begin = datetime.datetime.now()\n",
    "    ternode = addnode1(initnode=1)\n",
    "    end = datetime.datetime.now()\n",
    "    se = end - begin\n",
    "    time1  = np.append(time1,se.seconds)\n",
    "    node1 = np.append(node1,ternode)\n",
    "print('avarge time: ', time1.mean())\n",
    "print('avarge nodes: ', node1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# addnode2是加节点模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnode2(initnode):\n",
    "    dy_hidden_size  = 1 \n",
    "    init_train_acc = 0\n",
    "    init_test_acc = 0\n",
    "    for dy_hidden_size in range(1,200):\n",
    "        net2 = network(input_size, dy_hidden_size, num_classes)\n",
    "        stats = net2.train(X_train, y_train, X_val, y_val,\n",
    "                    num_iters=5000, batch_size=200,\n",
    "                    learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                    reg=0.25, verbose=False)\n",
    "\n",
    "        train_acc = (net2.predict(X_train) == y_train).mean()\n",
    "#         print('Train accuracy: ', train_acc)\n",
    "        test_acc = (net2.predict(X_test) == y_test).mean()\n",
    "#         print('test accuracy: ', test_acc)\n",
    "        if test_acc >0.95 and train_acc > test_acc:\n",
    "            print('Terminal hidden nodes number: ', dy_hidden_size)\n",
    "            break\n",
    "\n",
    "        dy_hidden_size = dy_hidden_size + 1\n",
    "\n",
    "       \n",
    "    return dy_hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  7\n",
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  11\n",
      "Terminal hidden nodes number:  12\n",
      "Terminal hidden nodes number:  11\n",
      "Terminal hidden nodes number:  11\n",
      "Terminal hidden nodes number:  10\n",
      "Terminal hidden nodes number:  8\n",
      "avarge time:  13.1\n",
      "avarge nodes:  10.0\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "time2 = []\n",
    "node2 = []\n",
    "for i in range(10):\n",
    "    begin = datetime.datetime.now()\n",
    "    ternode = addnode2(initnode=2)\n",
    "    end = datetime.datetime.now()\n",
    "    se = end - begin\n",
    "    time2  = np.append(time2,se.seconds)\n",
    "    node2 = np.append(node2,ternode)\n",
    "print('avarge time: ', time2.mean())\n",
    "print('avarge nodes: ', node2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义一个函数，扩充节点的时候，新节点的权重为0，这样保持输出期望一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnode3(initnode):\n",
    "    #扩充节点模式，之前训练的参数保留\n",
    "    dy_hidden_size  = initnode \n",
    "    init_train_acc = 0\n",
    "    init_test_acc = 0\n",
    "    net3 = network(input_size, dy_hidden_size, num_classes)\n",
    "    for i in range(1,200):\n",
    "        stats = net3.train(X_train, y_train, X_val, y_val,\n",
    "                    num_iters=5000, batch_size=200,\n",
    "                    learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                    reg=0.25, verbose=False)\n",
    "\n",
    "        train_acc = (net3.predict(X_train) == y_train).mean()\n",
    "#         print('Train accuracy: ', train_acc)\n",
    "        test_acc = (net3.predict(X_test) == y_test).mean()\n",
    "#         print('test accuracy: ', test_acc)\n",
    "        if test_acc >0.95 and train_acc > test_acc:\n",
    "            print('Terminal hidden nodes number: ', dy_hidden_size)\n",
    "            break\n",
    "\n",
    "        #增加一个隐藏层节点，就是给权重矩阵扩充一列\n",
    "        dy_hidden_size = dy_hidden_size + 1\n",
    "\n",
    "        #给输入层的权重矩阵增加一列,权重为已经训练过的节点的权重\n",
    "        c = net3.params_['W1'][:,0].reshape(64,1)\n",
    "        net3.params_['W1'] = np.hstack((net3.params_['W1'],c))\n",
    "        #给输入层的偏置增加一个0\n",
    "        net3.params_['b1'] = np.append(net3.params_['b1'], np.zeros(1))\n",
    "        #给输入层的权重矩阵增加一行,权重为0\n",
    "        d = net3.params_['W2'][0,:].reshape(1,10)\n",
    "        net3.params_['W2'] = np.vstack((net3.params_['W2'],d))\n",
    "    return dy_hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal hidden nodes number:  15\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "time3 = []\n",
    "node3 = []\n",
    "for i in range(10):\n",
    "    begin = datetime.datetime.now()\n",
    "    ternode = addnode3(initnode=2)\n",
    "    end = datetime.datetime.now()\n",
    "    se = end - begin\n",
    "    time3  = np.append(time3,se.seconds)\n",
    "    node3 = np.append(node3,ternode)\n",
    "print('avarge time: ', time3.mean())\n",
    "print('avarge nodes: ', node3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 做一个函数addnode4，每次扩张节点，把前面的权重都重新分配一下，新增的节点权重是前面所有的加起来求平均，原来的权重都要乘以n-1/n 这样期望不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnode4(initnode):\n",
    "    #扩充节点模式，之前训练的参数保留\n",
    "    dy_hidden_size  = initnode \n",
    "    init_train_acc = 0\n",
    "    init_test_acc = 0\n",
    "    net4 = network(input_size, dy_hidden_size, num_classes)\n",
    "    for i in range(1,200):\n",
    "        stats = net4.train(X_train, y_train, X_val, y_val,\n",
    "                    num_iters=5000, batch_size=200,\n",
    "                    learning_rate=0.01, learning_rate_decay=0.95,\n",
    "                    reg=0.25, verbose=False)\n",
    "\n",
    "        train_acc = (net4.predict(X_train) == y_train).mean()\n",
    "#         print('Train accuracy: ', train_acc)\n",
    "        test_acc = (net4.predict(X_test) == y_test).mean()\n",
    "#         print('test accuracy: ', test_acc)\n",
    "        if train_acc >0.96 and train_acc > test_acc:\n",
    "            print('Terminal hidden nodes number: ', dy_hidden_size)\n",
    "            break\n",
    "\n",
    "        #增加一个隐藏层节点，就是给权重矩阵扩充一列\n",
    "        p = dy_hidden_size/dy_hidden_size + 1\n",
    "        dy_hidden_size = dy_hidden_size + 1\n",
    "        \n",
    "        #给输入层的权重矩阵增加一列,权重为已经训练过的节点的权重的平均值（按行）,再把前面的做一个拉伸，乘以n-1/n\n",
    "        new = net4.params_['W1'].sum(axis=1)/dy_hidden_size\n",
    "        new = new.reshape(64,1)\n",
    "        old = net4.params_['W1']*p\n",
    "        net4.params_['W1'] = np.hstack((old,new))\n",
    "#         print(\"new=\",new)\n",
    "        #给输入层的偏置增加一个0\n",
    "        net4.params_['b1'] = np.append(net4.params_['b1'], np.zeros(1))\n",
    "        #给输入层的权重矩阵增加一行,权重为已经训练过的节点的权重的平均值（按列）,再把前面的做一个拉伸，乘以n-1/n\n",
    "        new1 = net4.params_['W2'].sum(axis=0)/dy_hidden_size\n",
    "        new1 = new1.reshape(1,10)\n",
    "        old1 = net4.params_['W2']*p\n",
    "#         print(\"new1=\",new1)\n",
    "        net4.params_['W2'] = np.vstack((old1,new1))\n",
    "    return dy_hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal hidden nodes number:  7\n",
      "Terminal hidden nodes number:  7\n",
      "Terminal hidden nodes number:  8\n",
      "Terminal hidden nodes number:  9\n",
      "Terminal hidden nodes number:  7\n",
      "Terminal hidden nodes number:  8\n",
      "Terminal hidden nodes number:  8\n",
      "Terminal hidden nodes number:  7\n",
      "Terminal hidden nodes number:  9\n",
      "Terminal hidden nodes number:  7\n",
      "avarge time:  8.4\n",
      "avarge nodes:  7.7\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "time4 = []\n",
    "node4 = []\n",
    "for i in range(10):\n",
    "    begin = datetime.datetime.now()\n",
    "    ternode = addnode4(initnode=2)\n",
    "    end = datetime.datetime.now()\n",
    "    se = end - begin\n",
    "    time4  = np.append(time4,se.seconds)\n",
    "    node4 = np.append(node4,ternode)\n",
    "print('avarge time: ', time4.mean())\n",
    "print('avarge nodes: ', node4.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
